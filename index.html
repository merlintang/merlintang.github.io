<!DOCTYPE html>
<html lang="en">
<head>
<meta charset="UTF-8" />
<meta name="viewport" content="width=device-width, initial-scale=1.0" />
<title>Mingjie Tang's Homepage</title>
<link href="defaultstyles.css" rel="stylesheet" media="screen" />
<script src="pub-authors.js" defer></script>
<script src="pub-filter.js" defer></script>
<script src="pub-summary.js" defer></script>
</head>

<body>

<!-- Hero Section -->
<section class="hero">
  <div class="hero-inner">
    <img src="mingjie_photo.JPG" alt="Mingjie Tang" class="hero-photo" />
    <div class="hero-text">
      <h1>Mingjie Tang</h1>
      <p class="hero-subtitle">Researcher &amp; Engineer &middot; LLM Systems &amp; Algorithms</p>
      <div class="hero-links">
        <a href="https://scholar.google.com/citations?user=tVgxEuwAAAAJ&hl=en" class="hero-link-pill">
          <svg viewBox="0 0 24 24" width="16" height="16" fill="currentColor"><path d="M12 24a7 7 0 1 1 0-14 7 7 0 0 1 0 14zm0-2a5 5 0 1 0 0-10 5 5 0 0 0 0 10zM1.5 9L12 1l10.5 8h-3v2.5L12 5.5 4.5 11.5V9z"/></svg>
          Google Scholar
        </a>
        <a href="http://dblp.uni-trier.de/pers/hd/t/Tang:MingJie" class="hero-link-pill">
          <svg viewBox="0 0 24 24" width="16" height="16" fill="currentColor"><path d="M3 6l9 4 9-4-9-4-9 4zm9 6L3 8v8l9 4 9-4V8l-9 4z"/></svg>
          DBLP
        </a>
        <a href="https://github.com/merlintang" class="hero-link-pill">
          <svg viewBox="0 0 24 24" width="16" height="16" fill="currentColor"><path d="M12 2C6.477 2 2 6.477 2 12c0 4.42 2.865 8.166 6.839 9.489.5.092.682-.217.682-.482 0-.237-.009-.866-.013-1.7-2.782.604-3.369-1.34-3.369-1.34-.454-1.156-1.11-1.463-1.11-1.463-.908-.62.069-.608.069-.608 1.003.07 1.531 1.03 1.531 1.03.892 1.529 2.341 1.088 2.91.832.092-.647.35-1.088.636-1.338-2.22-.253-4.555-1.11-4.555-4.943 0-1.091.39-1.984 1.029-2.683-.103-.253-.446-1.27.098-2.647 0 0 .84-.269 2.75 1.025A9.578 9.578 0 0 1 12 6.836a9.59 9.59 0 0 1 2.504.337c1.909-1.294 2.747-1.025 2.747-1.025.546 1.377.203 2.394.1 2.647.64.699 1.028 1.592 1.028 2.683 0 3.842-2.339 4.687-4.566 4.935.359.309.678.919.678 1.852 0 1.336-.012 2.415-.012 2.743 0 .267.18.578.688.48C19.138 20.163 22 16.418 22 12c0-5.523-4.477-10-10-10z"/></svg>
          GitHub
        </a>
        <span class="hero-link-pill hero-email" id="email-addr">
          <svg viewBox="0 0 24 24" width="16" height="16" fill="currentColor"><path d="M20 4H4c-1.1 0-2 .9-2 2v12c0 1.1.9 2 2 2h16c1.1 0 2-.9 2-2V6c0-1.1-.9-2-2-2zm0 4l-8 5-8-5V6l8 5 8-5v2z"/></svg>
        </span>
      </div>
    </div>
  </div>
</section>

<!-- Main Content -->
<main class="main-container">

  <nav class="site-nav">
    <a href="index.html" class="current">Home</a>
    <a href="page1.html#pub">Publication</a>
  </nav>

  <!-- About -->
  <section class="content-section fade-in">
    <h2 class="section-title">About</h2>
    <p>
      Mingjie Tang works on LLM systems and algorithms. He previously served as tech lead at Ant Group and as a member of the technical staff at Hortonworks/Cloudera. His research interests include database systems, distributed machine learning, big data computation, and distributed deep learning.
    </p>
    <p>
      He received his PhD in Computer Science from Purdue University, West Lafayette, Indiana, under the supervision of Professor <a href="https://www.cs.purdue.edu/homes/aref/">Walid G. Aref</a>. His doctoral research focused on distributed systems for spatial computation, machine learning, and artificial intelligence.
    </p>
  </section>

  <!-- Experience -->
  <section class="content-section fade-in">
    <h2 class="section-title">Industry Experience</h2>
    <div class="card">
      <div class="timeline">
        <div class="timeline-item">
          <span class="timeline-date">2025.11 - present</span>
          <span class="timeline-text">Researcher, Consultant, <a href="https://iquestlab.github.io/">iQuest Research Lab</a></span>
        </div>
        <div class="timeline-item">
          <span class="timeline-date">2018.10 - 2022.10</span>
          <span class="timeline-text">AI Engineer, Ant Group, CA, USA</span>
        </div>
        <div class="timeline-item">
          <span class="timeline-date">2016.9 - 2018.10</span>
          <span class="timeline-text">Member of tech staff, Hortonworks, CA, USA</span>
        </div>
        <div class="timeline-item">
          <span class="timeline-date">2015.5 - 2015.8</span>
          <span class="timeline-text">Research Intern, <a href="http://www.research.ibm.com/labs/almaden/">IBM Research Almaden</a>, CA, USA</span>
        </div>
        <div class="timeline-item">
          <span class="timeline-date">2012.5 - 2012.8</span>
          <span class="timeline-text">Software Engineer Intern, <a href="https://www.microsoft.com/en-us/">Microsoft</a>, Seattle, USA</span>
        </div>
      </div>
    </div>
  </section>

  <!-- Education -->
  <section class="content-section fade-in">
    <h2 class="section-title">Education</h2>
    <div class="card">
      <div class="timeline">
        <div class="timeline-item">
          <span class="timeline-date">2010.9 - 2016.9</span>
          <span class="timeline-text">PhD, <a href="http://www.purdue.edu/">Purdue University</a>, IN, USA</span>
        </div>
        <div class="timeline-item">
          <span class="timeline-date">2010.9 - 2012.12</span>
          <span class="timeline-text">M.S., <a href="http://www.purdue.edu/">Purdue University</a>, IN, USA</span>
        </div>
        <div class="timeline-item">
          <span class="timeline-date">2007.9 - 2010.7</span>
          <span class="timeline-text">M.S., <a href="http://english.ucas.ac.cn/Pages/default.aspx">University of Chinese Academy of Sciences</a>, Beijing, China</span>
        </div>
        <div class="timeline-item">
          <span class="timeline-date">2003.8 - 2007.7</span>
          <span class="timeline-text">B.S., <a href="http://www.scu.edu.cn/en/">Sichuan University</a>, Chengdu, China</span>
        </div>
      </div>
    </div>
  </section>

  <!-- Publications -->
  <section class="content-section fade-in" id="pub">
    <h2 class="section-title">Publication (Recent)</h2>
    <p><a href="https://scholar.google.com/citations?user=tVgxEuwAAAAJ&hl=en">Google Scholar</a>,
    <a href="http://dblp.uni-trier.de/pers/hd/t/Tang:MingJie">DBLP</a> â€”
    <a href="page1.html#pub">View all publications &rarr;</a>
    </p>

    <h4 class="pub-year">2026</h4>
<ul>
<li data-pub-tags="llm bigdata" data-pub-summary="A framework for training large language models at scale using thousands of accelerators in the cloud. It enables efficient pre-training and reduces resource waste.">
<b>DLRover-LM: LLM Pre-Training Framework with Thousands of Accelerators in AntGroup</b>
<br>
Ziling Huang, Zhengmao Ye, Qingsong Cai, Zelong Huang, Bo Sang, Haitao Zhang, Jian Sha, Tingfeng Lan, Hui Lu, Yuanchun Zhou, <strong>Mingjie Tang</strong>
<br>
<i>Proceedings of the IEEE International Conference on Data Engineering (ICDE '26), May 2026.</i>
</li>
</ul>

<ul>
<li data-pub-tags="llm database" data-pub-summary="Studies whether LLM-based Text-to-SQL systems are vulnerable to SQL injection via backdoor attacks. It also explores how to defend against such attacks.">
<b><a href="https://arxiv.org/abs/2503.05445">Are Your LLM-based Text-to-SQL Models Secure? Exploring SQL Injection via Backdoor Attacks</a></b>
<br>
Meiyu Lin, Haichuan Zhang, Jiale Lao, and Renyuan Li, Yuanchun Zhou, Carl Yang, Yang Cao, <strong>Mingjie Tang</strong>
<br>
<i> Proceedings of the ACM SIGMOD International Conference on Management of Data (SIGMOD '26), Jun 2026. </i>
</li>
</ul>

    <h4 class="pub-year">2025</h4>
<ul>
<li data-pub-tags="llm" data-pub-summary="A cost-effective pipeline for natural language transformation that relies more on prompting and less on heavy fine-tuning. It keeps training and inference flexible and cheap.">
<b><a href="https://aclanthology.org/2025.emnlp-main.737/">Tuning Less, Prompting More: A Cost-Effective and Flexible Training and Inference Pipeline for Natural Language Transformation</a></b>
<br>
Shuyun Yang, Zhengmao Ye, Yan Zhang, and Lei Duan, <strong>Mingjie Tang</strong>
<br>
<i> Proceedings of the 2025 Conference on Empirical Methods in Natural Language Processing (EMNLP '25), Nov 2025. </i>
</li>
</ul>

<ul>
<li data-pub-tags="llm" data-pub-summary="Uses reinforcement learning to produce concise, focused reasoning instead of long verbose outputs. This improves clarity and reduces token use.">
<b>
 Concise reasoning via reinforcement learning
</b>
<br>
Mehdi Fatemi, Banafsheh Rafiee, <strong>Mingjie Tang</strong>, Kartik Talamadupula
<br>
</li>
</ul>

<ul>
<li data-pub-tags="llm bigdata" data-pub-summary="Efficiently fine-tunes LoRA adapters for LLMs using pipeline parallelism across multiple GPUs. It speeds up training and uses GPU resources well.">
<b><a href="https://arxiv.org/abs/2312.02515">mLoRA: Fine-Tuning LoRA Adapters via Highly-Efficient Pipeline Parallelism in Multiple GPUs</a></b>
<br>
 Zhengmao Ye, Dengchun Li, Zetao Hu, Tingfen Lan, Sha Jian, Sicong Zheng, Lei Duan, Jie Zuo, Hui Lu, Yuanchun Zhou, <strong>Mingjie Tang</strong>
<br>
<i> Proceedings of Very Large Data Bases Conference (VLDB), 2025. </i>
</li>
</ul>

    <h4 class="pub-year">2024</h4>
<ul>
<li data-pub-tags="bigdata" data-pub-summary="Optimizes resource usage when training deep recommendation models in the cloud to reduce cost and improve throughput. It helps scale training on shared clusters.">
<b><a href="https://www.vldb.org/pvldb/vol17/p4130-tang.pdf">DLRover-RM: Resource Optimization for Deep Recommendation Models Training in Cloud</a></b>
<br>
  Qinlong Wang,  Tingfeng Lan, Yinghao Tang, Bo Sang, Ziling Huang, Yihen Du, Haitao Zhang, Shajian, Ke Zhang,  Hui Lu, Yuanchun Zhou, <strong>Mingjie Tang</strong>
<br>
 <i> Proceedings of Very Large Data Bases Conference (VLDB), 2024. </i>
</li>
</ul>

<ul>
<li data-pub-tags="llm" data-pub-summary="A black-box adversarial patch attack that works on pixel-wise regression tasks (e.g., depth or pose estimation). It shows how such models can be fooled by patches.">
<b><a href="https://arxiv.org/abs/2404.00924">BadPart: Unified Black-box Adversarial Patch Attacks against Pixel-wise Regression Tasks</a></b>
<br>
Zhiyuan Cheng, Zhaoyi Liu, Tengda Guo, Shiwei Feng, Dongfang Liu,<strong>Mingjie Tang</strong>, Xiangyu Zhang
<br>
 <i> International Conference on Machine Learning  (ICML), 2024. </i>
</li>
</ul>



<ul>
<li data-pub-tags="llm database" data-pub-summary="Demo of a system that uses GPT to read database manuals and guide tuning decisions via Bayesian optimization. Users can tune databases with minimal manual expertise.">
<b><a href="https://dl.acm.org/doi/10.1145/3626246.3654739">A Demonstration of GPTuner: A GPT-Based Manual-Reading Database Tuning System</a></b>
<br>
Jiale Lao, Yibo Wang, Yufei Li, Jianping Wang, Yunjia Zhang, Zhiyuan Cheng, Wanghu Chen, Yuanchun Zhou, <strong>Mingjie Tang</strong>, Jianguo Wang
<br>
Demo <i> Proceedings of ACM Conference on Management of Data (SIGMOD), 2024. </i>
</li>
</ul>

<ul>
  <li data-pub-tags="llm database" data-pub-summary="Uses GPT to interpret database manuals and guide Bayesian optimization for automatic database parameter tuning. It reduces the need for human tuning experts.">
    <b><a href="https://arxiv.org/abs/2311.03157">GPTuner: A Manual-Reading Database Tuning System via GPT-Guided Bayesian Optimization</a></b><br>
    Jiale Lao, Yibo Wang, Yufei Li, Jianping Wang, Yunjia Zhang, Zhiyuan Cheng, Wanghu Chen, <strong>Mingjie Tang</strong>, Jianguo Wang<br>
    <i>Proceedings of Very Large Data Bases Conference (VLDB), 2024.</i><br>
    <font color="#ff0000"><b>&#127942; Selected for SIGMOD Research Highlight Awards 2025!</b></font>
  </li>
</ul>

<ul>
<li data-pub-tags="bigdata" data-pub-summary="Unified system for defining and optimizing machine learning workflows in the cloud. It simplifies building and running ML pipelines at scale.">
<b><a href="https://arxiv.org/abs/2403.07608">Couler: Unified Machine Learning Workflow Optimization in Cloud</a></b>
<br>
 Xiaoda Wang, Yuan Tang, Tengda Guo, Bo Sang, Jingji Wu, Jian Sha, Ke Zhang, Jiang Qian, <strong>Mingjie Tang</strong>
<br>
<i> 40th IEEE International Conference on Data Engineering (ICDE) 2024 </i>
</li>
</ul>

    <h4 class="pub-year">2023</h4>
<ul>
<li data-pub-tags="bigdata" data-pub-summary="A general framework for optimizing jobs and workloads in cloud environments. It improves efficiency and resource use for diverse workloads.">
<b><a href="https://ieeexplore.ieee.org/document/10184667">Cougar: A General Framework for Jobs Optimization In Cloud</a></b>
<br>
Bo Sang, Shuwei Gu, Xiaojun Zhan, <strong>Mingjie Tang</strong>, Jian Liu, Xuan Chen, Jie Tan, Haoyuan Ge, Ke Zhang, Ruoyi Ruan, Wei Yan
<br>
<i> 39th IEEE International Conference on Data Engineering (ICDE) 2023 </i>
</li>
</ul>
  </section>

</main>

<!-- Footer -->
<footer class="site-footer">
  <span>&copy; Mingjie Tang</span>
  <span class="footer-ai">&middot; Built with AI vibe coding</span>
</footer>

<script src="email.js"></script>
</body>
</html>
